{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_ASSIGN4_ACTIVITY1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOELITJWUBf3nS4vQmDw36",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvthe-elegant/deep_learning/blob/Assignment_4/DL_ASSIGN4_ACTIVITY1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snDTJsv890V5"
      },
      "source": [
        "## **20MAI0038**\n",
        "## **Rahul Laxman Vasanad**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxNB-L-u9zZJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASyC8CQX9tIS"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d5Bq9aV-LCx",
        "outputId": "1d74c9db-6043-4e3d-f658-167f4bc0098a"
      },
      "source": [
        "#Instantiation\n",
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(4096))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(10))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CLj4LRn-Rw_"
      },
      "source": [
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5bOV7oF-WP4",
        "outputId": "7afd4342-ab83-46c6-f8fa-02401fe08dbd"
      },
      "source": [
        "#Keras library for CIFAR dataset\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train),(x_test, y_test)=cifar10.load_data()\n",
        "\n",
        "#Train-validation-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "\n",
        "\n",
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XahB10_1-cMZ",
        "outputId": "0bfe09ce-0f65-4fac-b837-899d46a9be2e"
      },
      "source": [
        "#Onehot Encoding the labels.\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#Since we have 10 classes we should expect the shape[1] of y_train,y_val and y_test to change from 1 to 10\n",
        "y_train=to_categorical(y_train)\n",
        "y_val=to_categorical(y_val)\n",
        "y_test=to_categorical(y_test)\n",
        "\n",
        "#Verifying the dimension after one hot encoding\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 10))\n",
            "((15000, 32, 32, 3), (15000, 10))\n",
            "((10000, 32, 32, 3), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rySgxjNE_Gn1",
        "outputId": "5b579d83-b850-4dc1-ac92-204bbe047a71"
      },
      "source": [
        "#Defining the parameters\n",
        "batch_size= 100\n",
        "epochs=20\n",
        "#Training the model\n",
        "AlexNet.fit(x_train, y_train,\n",
        "batch_size=batch_size,\n",
        "epochs=epochs,\n",
        "verbose=1,\n",
        "validation_data=(x_val, y_val))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "350/350 [==============================] - 20s 57ms/step - loss: 0.9393 - accuracy: 0.6828 - val_loss: 1.8595 - val_accuracy: 0.4038\n",
            "Epoch 2/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.8481 - accuracy: 0.7142 - val_loss: 2.4910 - val_accuracy: 0.3327\n",
            "Epoch 3/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.7659 - accuracy: 0.7439 - val_loss: 1.4586 - val_accuracy: 0.5245\n",
            "Epoch 4/20\n",
            "350/350 [==============================] - 20s 57ms/step - loss: 0.6815 - accuracy: 0.7752 - val_loss: 1.6635 - val_accuracy: 0.4806\n",
            "Epoch 5/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.6037 - accuracy: 0.8026 - val_loss: 1.6515 - val_accuracy: 0.5012\n",
            "Epoch 6/20\n",
            "350/350 [==============================] - 19s 56ms/step - loss: 0.5299 - accuracy: 0.8277 - val_loss: 2.8115 - val_accuracy: 0.3245\n",
            "Epoch 7/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.4590 - accuracy: 0.8516 - val_loss: 1.3081 - val_accuracy: 0.5946\n",
            "Epoch 8/20\n",
            "350/350 [==============================] - 19s 56ms/step - loss: 0.3984 - accuracy: 0.8731 - val_loss: 2.0796 - val_accuracy: 0.4345\n",
            "Epoch 9/20\n",
            "350/350 [==============================] - 19s 56ms/step - loss: 0.3517 - accuracy: 0.8886 - val_loss: 2.0234 - val_accuracy: 0.4617\n",
            "Epoch 10/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.3010 - accuracy: 0.9065 - val_loss: 2.1374 - val_accuracy: 0.4437\n",
            "Epoch 11/20\n",
            "350/350 [==============================] - 19s 56ms/step - loss: 0.2658 - accuracy: 0.9194 - val_loss: 1.8649 - val_accuracy: 0.5039\n",
            "Epoch 12/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.2501 - accuracy: 0.9230 - val_loss: 2.2420 - val_accuracy: 0.4277\n",
            "Epoch 13/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.2171 - accuracy: 0.9312 - val_loss: 1.8629 - val_accuracy: 0.5154\n",
            "Epoch 14/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.1948 - accuracy: 0.9405 - val_loss: 2.5471 - val_accuracy: 0.4223\n",
            "Epoch 15/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.1860 - accuracy: 0.9425 - val_loss: 2.0517 - val_accuracy: 0.4736\n",
            "Epoch 16/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.1642 - accuracy: 0.9497 - val_loss: 1.5133 - val_accuracy: 0.5989\n",
            "Epoch 17/20\n",
            "350/350 [==============================] - 19s 56ms/step - loss: 0.1462 - accuracy: 0.9549 - val_loss: 1.7225 - val_accuracy: 0.5622\n",
            "Epoch 18/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.1549 - accuracy: 0.9527 - val_loss: 1.7239 - val_accuracy: 0.5572\n",
            "Epoch 19/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.1351 - accuracy: 0.9573 - val_loss: 2.0460 - val_accuracy: 0.5152\n",
            "Epoch 20/20\n",
            "350/350 [==============================] - 20s 56ms/step - loss: 0.1228 - accuracy: 0.9631 - val_loss: 2.0868 - val_accuracy: 0.5017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f62611829d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiTNdM2IGLPT",
        "outputId": "832be701-57bd-4612-d0be-13b57ec44c4c"
      },
      "source": [
        "AlexNet.evaluate(x_test,y_test)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 4s 10ms/step - loss: 2.1016 - accuracy: 0.4979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.1015961170196533, 0.49790000915527344]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4j9FY0cGRgp"
      },
      "source": [
        "!mkdir -p saved_model\n",
        "AlexNet.save('saved_model/AlexNetModel.h5') \n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yybMWOagGZWp"
      },
      "source": [
        "# **Transfer Learning using the AlexNet Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLEfZrQrGWAu"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrwE1sbqGeWy"
      },
      "source": [
        "Base_model = tf.keras.models.load_model('saved_model/AlexNetModel.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpG02VKNFK15",
        "outputId": "3fccdf0e-01f1-4d32-e0d3-5a451da126f9"
      },
      "source": [
        "(X_train,Y_train), (X_valid, Y_valid) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# expand new axis, channel axis \n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "X_train = np.repeat(X_train, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_train = X_train.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "X_train = tf.image.resize(X_train, [32,32]) # if we want to resize \n",
        "\n",
        "print(X_train.shape)\n",
        "\n",
        "X_valid = np.expand_dims(X_valid, axis=-1)\n",
        "\n",
        "# [optional]: we may need 3 channel (instead of 1)\n",
        "X_valid = np.repeat(X_valid, 3, axis=-1)\n",
        "\n",
        "# it's always better to normalize \n",
        "X_valid = X_valid.astype('float32') / 255\n",
        "\n",
        "# resize the input shape , i.e. old shape: 28, new shape: 32\n",
        "X_valid = tf.image.resize(X_valid, [32,32]) # if we want to resize \n",
        "\n",
        "print(X_valid.shape)\n",
        "\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "Y_train = np_utils.to_categorical(Y_train, num_classes=10)\n",
        "Y_valid = np_utils.to_categorical(Y_valid, num_classes=10)\n",
        "\n",
        "print((X_train.shape,Y_train.shape))\n",
        "print((X_valid.shape,Y_valid.shape))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "(TensorShape([60000, 32, 32, 3]), (60000, 10))\n",
            "(TensorShape([10000, 32, 32, 3]), (10000, 10))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xN9_hBiKJvQq"
      },
      "source": [
        "from keras.models import load_model\n",
        "new_model = load_model(\"saved_model/AlexNetModel.h5\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iROqptpEJv2B",
        "outputId": "346d4f3e-b6ca-4c93-af78-7b4fa387d3c6"
      },
      "source": [
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 2, 2, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 2, 2, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 2, 2, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 2, 2, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1000)              4097000   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 1000)              4000      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                10010     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 10)                40        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 25,730,506\n",
            "Trainable params: 25,709,350\n",
            "Non-trainable params: 21,156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXgo4x_2KAxp",
        "outputId": "328e0613-77ef-43b0-9f1e-7222dab9d0e9"
      },
      "source": [
        "new_model.trainable=False\n",
        "model = tf.keras.Sequential([\n",
        "    new_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential (Sequential)      (None, 10)                25730506  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                110       \n",
            "=================================================================\n",
            "Total params: 25,730,616\n",
            "Trainable params: 110\n",
            "Non-trainable params: 25,730,506\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi2PqAQ2KG9O",
        "outputId": "de5d8dcc-1560-4748-8490-39931868e5fa"
      },
      "source": [
        "history = model.fit(X_train, Y_train,\n",
        "batch_size=100,\n",
        "epochs=20,\n",
        "verbose=1,\n",
        "validation_data=(X_valid, Y_valid))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "600/600 [==============================] - 11s 17ms/step - loss: 2.3087 - accuracy: 0.1026 - val_loss: 2.3004 - val_accuracy: 0.1135\n",
            "Epoch 2/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3016 - accuracy: 0.1102 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 3/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3019 - accuracy: 0.1078 - val_loss: 2.3005 - val_accuracy: 0.1135\n",
            "Epoch 4/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3014 - accuracy: 0.1099 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 5/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3016 - accuracy: 0.1083 - val_loss: 2.3000 - val_accuracy: 0.1135\n",
            "Epoch 6/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3013 - accuracy: 0.1098 - val_loss: 2.3003 - val_accuracy: 0.1135\n",
            "Epoch 7/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3009 - accuracy: 0.1126 - val_loss: 2.3001 - val_accuracy: 0.1135\n",
            "Epoch 8/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3008 - accuracy: 0.1120 - val_loss: 2.3000 - val_accuracy: 0.1135\n",
            "Epoch 9/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3008 - accuracy: 0.1109 - val_loss: 2.3001 - val_accuracy: 0.1135\n",
            "Epoch 10/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3003 - accuracy: 0.1122 - val_loss: 2.2999 - val_accuracy: 0.1135\n",
            "Epoch 11/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3005 - accuracy: 0.1138 - val_loss: 2.3001 - val_accuracy: 0.1135\n",
            "Epoch 12/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3011 - accuracy: 0.1119 - val_loss: 2.2999 - val_accuracy: 0.1135\n",
            "Epoch 13/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3003 - accuracy: 0.1144 - val_loss: 2.3000 - val_accuracy: 0.1135\n",
            "Epoch 14/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3003 - accuracy: 0.1151 - val_loss: 2.3000 - val_accuracy: 0.1135\n",
            "Epoch 15/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3007 - accuracy: 0.1142 - val_loss: 2.3000 - val_accuracy: 0.1135\n",
            "Epoch 16/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3005 - accuracy: 0.1146 - val_loss: 2.2999 - val_accuracy: 0.1135\n",
            "Epoch 17/20\n",
            "600/600 [==============================] - 9s 16ms/step - loss: 2.3009 - accuracy: 0.1121 - val_loss: 2.2999 - val_accuracy: 0.1135\n",
            "Epoch 18/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3006 - accuracy: 0.1136 - val_loss: 2.2998 - val_accuracy: 0.1135\n",
            "Epoch 19/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3009 - accuracy: 0.1125 - val_loss: 2.2998 - val_accuracy: 0.1135\n",
            "Epoch 20/20\n",
            "600/600 [==============================] - 10s 16ms/step - loss: 2.3007 - accuracy: 0.1118 - val_loss: 2.2999 - val_accuracy: 0.1135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO_Ut-4bKLXI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}