{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign2_Activity1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7KodKAsDoJT9F30MVZ0p/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvthe-elegant/deep_learning/blob/Assignment_2/DL_Assign2_Activity1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymkUk2ghrTeF"
      },
      "source": [
        "## **Sigmoid Activation Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9mRlhLIPf4L",
        "outputId": "70e44a22-d1d6-4e9c-c1c1-4a8fe50ff0a9"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        #applying the sigmoid function\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        #computing derivative to the Sigmoid function\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs, 15000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    user_input_one = str(input(\"User Input One: \"))\n",
        "    user_input_two = str(input(\"User Input Two: \"))\n",
        "    user_input_three = str(input(\"User Input Three: \"))\n",
        "    \n",
        "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
        "    print(\"New Output data: \")\n",
        "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
        "    print(\"Wow, we did it!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[10.08740896]\n",
            " [-0.20695366]\n",
            " [-4.83757835]]\n",
            "User Input One: 1\n",
            "User Input Two: 0\n",
            "User Input Three: 0\n",
            "Considering New Situation:  1 0 0\n",
            "New Output data: \n",
            "[0.9999584]\n",
            "Wow, we did it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaZagY_8Te4j"
      },
      "source": [
        "# Tanh Activation Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWp2F1UwTlju",
        "outputId": "8bafb865-309c-4711-bea6-6e0400d079dc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def tanh(self, x):\n",
        "        #applying the tanh function\n",
        "        return (2 / (1 + np.exp(-2*x))) - 1\n",
        "\n",
        "    def tanh_derivative(self, x):\n",
        "        #computing derivative to the tanh function\n",
        "        return 1 - (x*x)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.tanh_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.tanh(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs, 15000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    user_input_one = str(input(\"User Input One: \"))\n",
        "    user_input_two = str(input(\"User Input Two: \"))\n",
        "    user_input_three = str(input(\"User Input Three: \"))\n",
        "    \n",
        "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
        "    print(\"New Output data: \")\n",
        "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
        "    print(\"Wow, we did it!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[ 3.70829131]\n",
            " [-0.18256004]\n",
            " [-0.32370443]]\n",
            "User Input One: 1\n",
            "User Input Two: 0\n",
            "User Input Three: 0\n",
            "Considering New Situation:  1 0 0\n",
            "New Output data: \n",
            "[0.99879832]\n",
            "Wow, we did it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRciL_BfUGZt"
      },
      "source": [
        "# Hyperbolic Tangent Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCNJs2FhUOR-",
        "outputId": "ce7689d9-1c91-472c-cc29-6809230952f7"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def hyperbolic_tangent(self, x):\n",
        "        #applying the hyperbolic tangent function\n",
        "        return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "    def hyperbolic_derivative(self, x):\n",
        "        #computing derivative to the hyperbolic tangent function\n",
        "        return 1-(x*x)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.hyperbolic_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.hyperbolic_tangent(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs, 15000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    user_input_one = str(input(\"User Input One: \"))\n",
        "    user_input_two = str(input(\"User Input Two: \"))\n",
        "    user_input_three = str(input(\"User Input Three: \"))\n",
        "    \n",
        "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
        "    print(\"New Output data: \")\n",
        "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
        "    print(\"Wow, we did it!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[ 3.70829131]\n",
            " [-0.18256004]\n",
            " [-0.32370443]]\n",
            "User Input One: 1\n",
            "User Input Two: 0\n",
            "User Input Three: 0\n",
            "Considering New Situation:  1 0 0\n",
            "New Output data: \n",
            "[0.99879832]\n",
            "Wow, we did it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w47Yej4ZYR0b"
      },
      "source": [
        "## **Relu Activation Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAQfhq_uYZK4",
        "outputId": "160d2928-dbc3-420f-865f-ca6d6e147076"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def Leaky_relu(self, x):\n",
        "        #applying the Leaky relu function\n",
        "       return np.where(x > 0, x, 0)\n",
        "\n",
        "    def Leaky_relu_derivative(self, x):\n",
        "        #computing derivative to the Leaky_relu function\n",
        "        return np.max(x,0)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.Leaky_relu_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.Leaky_relu(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs, 15000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    user_input_one = str(input(\"User Input One: \"))\n",
        "    user_input_two = str(input(\"User Input0 Two: \"))\n",
        "    user_input_three = str(input(\"User Input Three: \"))\n",
        "    \n",
        "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
        "    print(\"New Output data: \")\n",
        "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
        "    print(\"Wow, we did it!\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "User Input One: 0\n",
            "User Input0 Two: 1\n",
            "User Input Three: 0\n",
            "Considering New Situation:  0 1 0\n",
            "New Output data: \n",
            "[0.44064899]\n",
            "Wow, we did it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jvJgKIFr2jk"
      },
      "source": [
        "1## **Leaky ReLu Activation Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IlZga7dUsvD",
        "outputId": "19f0e157-55ee-4131-f160-2373e86d9822"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def Leaky_relu(self, x):\n",
        "        #applying the Leaky relu function\n",
        "       return np.where(x > 0, x, x * 0.01)\n",
        "\n",
        "    def Leaky_relu_derivative(self, x):\n",
        "        #computing derivative to the Leaky_relu function\n",
        "        return np.where(x > 0, x,  0.01)\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.Leaky_relu_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.Leaky_relu(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs, 15000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    user_input_one = str(input(\"User Input One: \"))\n",
        "    user_input_two = str(input(\"User Input0 Two: \"))\n",
        "    user_input_three = str(input(\"User Input Three: \"))\n",
        "    \n",
        "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
        "    print(\"New Output data: \")\n",
        "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
        "    print(\"Wow, we did it!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[ 0.54072482]\n",
            " [-0.46046312]\n",
            " [-0.83025092]]\n",
            "User Input One: 1\n",
            "User Input Two: 0\n",
            "User Input Three: 0\n",
            "Considering New Situation:  1 0 0\n",
            "New Output data: \n",
            "[0.54072482]\n",
            "Wow, we did it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVYTBM8aZrZr"
      },
      "source": [
        "## **Exponential Function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3nwXPFrV4wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "477a029b-396f-4967-e488-a86965be90e2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # seeding for random number generation\n",
        "        np.random.seed(1)\n",
        "        \n",
        "        #converting weights to a 3 by 1 matrix with values from -1 to 1 and mean of 0\n",
        "        self.synaptic_weights = 2 * np.random.random((3, 1)) - 1\n",
        "\n",
        "    def hyperbolic_tangent(self, x):\n",
        "        #applying the hyperbolic tangent function\n",
        "       return np.where(x>=0,x,0.01*(np.exp(x) -1))\n",
        "\n",
        "    def hyperbolic_derivative(self, x):\n",
        "        #computing derivative to the hyperbolic tangent function\n",
        "        return np.where(x>0,1,0.01*np.exp(x))\n",
        "\n",
        "    def train(self, training_inputs, training_outputs, training_iterations):\n",
        "        \n",
        "        #training the model to make accurate predictions while adjusting weights continually\n",
        "        for iteration in range(training_iterations):\n",
        "            #siphon the training data via  the neuron\n",
        "            output = self.think(training_inputs)\n",
        "\n",
        "            #computing error rate for back-propagation\n",
        "            error = training_outputs - output\n",
        "            \n",
        "            #performing weight adjustments\n",
        "            adjustments = np.dot(training_inputs.T, error * self.hyperbolic_derivative(output))\n",
        "\n",
        "            self.synaptic_weights += adjustments\n",
        "\n",
        "    def think(self, inputs):\n",
        "        #passing the inputs via the neuron to get output   \n",
        "        #converting values to floats\n",
        "        \n",
        "        inputs = inputs.astype(float)\n",
        "        output = self.hyperbolic_tangent(np.dot(inputs, self.synaptic_weights))\n",
        "        return output\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #initializing the neuron class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print(\"Beginning Randomly Generated Weights: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    #training data consisting of 4 examples--3 input values and 1 output\n",
        "    training_inputs = np.array([[0,0,1],\n",
        "                                [1,1,1],\n",
        "                                [1,0,1],\n",
        "                                [0,1,1]])\n",
        "\n",
        "    training_outputs = np.array([[0,1,1,0]]).T\n",
        "\n",
        "    #training taking place\n",
        "    neural_network.train(training_inputs, training_outputs, 15000)\n",
        "\n",
        "    print(\"Ending Weights After Training: \")\n",
        "    print(neural_network.synaptic_weights)\n",
        "\n",
        "    user_input_one = str(input(\"User Input One: \"))\n",
        "    user_input_two = str(input(\"User Input Two: \"))\n",
        "    user_input_three = str(input(\"User Input Three: \"))\n",
        "    \n",
        "    print(\"Considering New Situation: \", user_input_one, user_input_two, user_input_three)\n",
        "    print(\"New Output data: \")\n",
        "    print(neural_network.think(np.array([user_input_one, user_input_two, user_input_three])))\n",
        "    print(\"Wow, we did it!\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Randomly Generated Weights: \n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Ending Weights After Training: \n",
            "[[ 2.00703346]\n",
            " [-0.97294624]\n",
            " [-0.0040815 ]]\n",
            "User Input One: 1\n",
            "User Input Two: 1\n",
            "User Input Three: 0\n",
            "Considering New Situation:  1 1 0\n",
            "New Output data: \n",
            "[1.03408722]\n",
            "Wow, we did it!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tnRwgMKabhT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}